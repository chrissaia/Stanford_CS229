{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lesson 12: Kernels (Concept + Demo)",
        "",
        "## Objectives",
        "- Implement an RBF kernel.",
        "- Use kernel ridge regression to model nonlinear data.",
        "- Visualize the kernel matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## From the notes",
        "The kernel trick replaces inner products \\(x^T z\\) with \\(K(x, z)\\).",
        "Example RBF kernel:",
        "\\[",
        "K(x, z) = \\exp\\left(-\frac{\\|x - z\\|^2}{2\\sigma^2}\right).",
        "\\]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intuition",
        "Kernels implicitly map data into high-dimensional feature spaces while avoiding explicit computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data",
        "We generate a nonlinear 1D dataset to motivate kernels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Nonlinear data",
        "m = 60",
        "X_raw = np.linspace(-3, 3, m)",
        "y = np.sin(X_raw) + np.random.normal(0, 0.2, size=m)",
        "X = X_raw[:, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation: kernel ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def rbf_kernel(X1, X2, sigma=1.0):",
        "    X1_sq = np.sum(X1**2, axis=1)[:, None]",
        "    X2_sq = np.sum(X2**2, axis=1)[None, :]",
        "    dists = X1_sq + X2_sq - 2 * X1 @ X2.T",
        "    return np.exp(-dists / (2 * sigma**2))",
        "",
        "",
        "def kernel_ridge_predict(X_train, y_train, X_test, lam=0.1, sigma=1.0):",
        "    K = rbf_kernel(X_train, X_train, sigma)",
        "    alpha = np.linalg.pinv(K + lam * np.eye(len(X_train))) @ y_train",
        "    K_test = rbf_kernel(X_test, X_train, sigma)",
        "    return K_test @ alpha, K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_test = np.linspace(-3, 3, 200)[:, None]",
        "preds, K = kernel_ridge_predict(X, y, X_test, lam=0.1, sigma=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))",
        "plt.scatter(X_raw, y, alpha=0.6, label=\"data\")",
        "plt.plot(X_test[:,0], preds, color=\"C1\", label=\"kernel ridge\")",
        "plt.xlabel(\"x\")",
        "plt.ylabel(\"y\")",
        "plt.title(\"Kernel regression fit\")",
        "plt.legend()",
        "plt.show()",
        "",
        "plt.figure(figsize=(5,4))",
        "plt.imshow(K, cmap=\"viridis\", aspect=\"auto\")",
        "plt.colorbar()",
        "plt.title(\"RBF kernel matrix\")",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways",
        "- Kernel methods provide nonlinear decision boundaries with linear algorithms.",
        "- The kernel matrix encodes similarity between points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explain it in an interview",
        "- Explain the kernel trick and RBF kernel shape.",
        "- Mention that kernel ridge regression solves a linear system in \\(m\\) points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises",
        "1. Change \\(\\sigma\\) and observe smoothness of the fit.",
        "2. Try a polynomial kernel and compare results.",
        "3. Discuss computational limits when \\(m\\) is large."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}