{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lesson 05 - Perceptron, Exponential Family, GLMs\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Objectives\n- Implement the perceptron algorithm.\n- Summarize exponential family distributions and GLM structure.\n- Connect link functions to mean parameters.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## From the notes\n\n**Perceptron update**\n- If $y^{(i)} (\\theta^T x^{(i)}) \\le 0$, update $\\theta := \\theta + \\alpha y^{(i)} x^{(i)}$.\n\n**GLM template**\n- Choose exponential family distribution.\n- Define $\\eta = \\theta^T x$ and link $g(\\mu) = \\eta$.\n\n_TODO: Confirm notation with the official CS229 main notes PDF._\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Intuition\nPerceptron is a simple linear classifier updated only on mistakes. GLMs generalize linear models by changing the output distribution and link function.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data\nWe use a linearly separable synthetic dataset to demonstrate the perceptron updates.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nX_pos = np.random.multivariate_normal([2, 2], np.eye(2), 50)\nX_neg = np.random.multivariate_normal([-2, -2], np.eye(2), 50)\nX = np.vstack([X_pos, X_neg])\ny = np.hstack([np.ones(50), -np.ones(50)])\nXb = np.c_[np.ones(len(X)), X]\n\ndef perceptron(X, y, epochs=10, alpha=0.1):\n    theta = np.zeros(X.shape[1])\n    for _ in range(epochs):\n        for xi, yi in zip(X, y):\n            if yi * (theta @ xi) <= 0:\n                theta += alpha * yi * xi\n    return theta\n\ntheta = perceptron(Xb, y)\ntheta\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Experiments\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Compare perceptron accuracy\npreds = np.sign(Xb @ theta)\nacc = (preds == y).mean()\nacc\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualizations\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "plt.figure(figsize=(6,4))\nplt.scatter(X_pos[:,0], X_pos[:,1], label=\"+1\")\nplt.scatter(X_neg[:,0], X_neg[:,1], label=\"-1\")\nx1 = np.linspace(-4, 4, 100)\nx2 = -(theta[0] + theta[1]*x1) / theta[2]\nplt.plot(x1, x2, color=\"black\", label=\"perceptron\")\nplt.title(\"Perceptron decision boundary\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(6,4))\nmargins = y * (Xb @ theta)\nplt.hist(margins, bins=15, alpha=0.7)\nplt.title(\"Perceptron margins\")\nplt.xlabel(\"y*(\u03b8^T x)\")\nplt.ylabel(\"count\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Takeaways\n- Perceptron is mistake-driven and finds any separating hyperplane if data is separable.\n- GLMs unify linear prediction with different output distributions through link functions.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explain it in an interview\n- Explain the perceptron update rule and when it converges.\n- Describe how you would choose a link function in a GLM.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n- Compare perceptron to logistic regression on a non-separable dataset.\n- Write down the exponential family form for Poisson.\n- Show that logistic regression is a GLM with Bernoulli output.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}