{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lesson 19: Evaluation (ROC/PR, Confusion Matrix)",
        "",
        "## Objectives",
        "- Compute confusion matrix, precision, recall.",
        "- Plot ROC and PR curves.",
        "- Understand threshold tradeoffs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## From the notes",
        "Evaluation uses metrics that trade off false positives and false negatives; ROC plots TPR vs FPR, PR plots precision vs recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intuition",
        "Changing the decision threshold moves you along ROC/PR curves; the best threshold depends on the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data",
        "We simulate predicted scores and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Synthetic scores",
        "m = 200",
        "scores = np.random.rand(m)",
        "y = (scores + 0.2*np.random.randn(m) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation: metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def confusion_matrix(y_true, y_pred):",
        "    tp = np.sum((y_true==1) & (y_pred==1))",
        "    fp = np.sum((y_true==0) & (y_pred==1))",
        "    tn = np.sum((y_true==0) & (y_pred==0))",
        "    fn = np.sum((y_true==1) & (y_pred==0))",
        "    return tp, fp, tn, fn",
        "",
        "",
        "def roc_pr(y_true, scores):",
        "    thresholds = np.linspace(0,1,50)",
        "    tpr, fpr, prec, rec = [], [], [], []",
        "    for t in thresholds:",
        "        y_pred = (scores >= t).astype(int)",
        "        tp, fp, tn, fn = confusion_matrix(y_true, y_pred)",
        "        tpr.append(tp / (tp + fn + 1e-9))",
        "        fpr.append(fp / (fp + tn + 1e-9))",
        "        prec.append(tp / (tp + fp + 1e-9))",
        "        rec.append(tp / (tp + fn + 1e-9))",
        "    return np.array(fpr), np.array(tpr), np.array(prec), np.array(rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fpr, tpr, prec, rec = roc_pr(y, scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))",
        "plt.plot(fpr, tpr, label=\"ROC\")",
        "plt.plot([0,1],[0,1],'k--')",
        "plt.xlabel(\"FPR\")",
        "plt.ylabel(\"TPR\")",
        "plt.title(\"ROC curve\")",
        "plt.legend()",
        "plt.show()",
        "",
        "plt.figure(figsize=(6,4))",
        "plt.plot(rec, prec, label=\"PR\")",
        "plt.xlabel(\"Recall\")",
        "plt.ylabel(\"Precision\")",
        "plt.title(\"Precision-Recall curve\")",
        "plt.legend()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways",
        "- ROC is useful for balanced classes; PR highlights performance on positives.",
        "- Thresholding controls the tradeoff between precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explain it in an interview",
        "- Define precision/recall and interpret ROC vs PR.",
        "- Describe how to pick thresholds for specific costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises",
        "1. Compute F1 score across thresholds and pick the best.",
        "2. Simulate class imbalance and compare ROC vs PR.",
        "3. Plot the confusion matrix at a chosen threshold."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}