{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lesson 14: PCA via SVD",
        "",
        "## Objectives",
        "- Implement PCA using SVD.",
        "- Visualize variance explained by components.",
        "- Project data to 1D and reconstruct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## From the notes",
        "PCA finds orthonormal directions maximizing variance. Using SVD of \\(X\\), principal components are the top right singular vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intuition",
        "PCA rotates the coordinate system to capture most variance in fewer dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data",
        "We generate correlated 2D data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Correlated data",
        "m = 120",
        "X = np.random.multivariate_normal([0,0], [[3,2.5],[2.5,2]], size=m)",
        "X_centered = X - X.mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation: PCA via SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)",
        "components = Vt",
        "explained_variance = (S**2) / (m - 1)",
        "explained_ratio = explained_variance / explained_variance.sum()",
        "",
        "# Project to 1D",
        "X_proj = X_centered @ components[0].T",
        "X_recon = np.outer(X_proj, components[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))",
        "plt.scatter(X[:,0], X[:,1], alpha=0.6)",
        "plt.quiver(0,0, components[0,0], components[0,1], scale=3, color=\"C1\", label=\"PC1\")",
        "plt.quiver(0,0, components[1,0], components[1,1], scale=3, color=\"C2\", label=\"PC2\")",
        "plt.title(\"PCA directions\")",
        "plt.legend()",
        "plt.show()",
        "",
        "plt.figure(figsize=(6,4))",
        "plt.bar([\"PC1\",\"PC2\"], explained_ratio)",
        "plt.ylabel(\"variance explained\")",
        "plt.title(\"Explained variance ratio\")",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways",
        "- PCA uses SVD to find directions of maximal variance.",
        "- Explained variance helps choose dimensionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explain it in an interview",
        "- Describe centering data and applying SVD.",
        "- Connect eigenvalues to variance explained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises",
        "1. Project to 2D from a 3D dataset and reconstruct.",
        "2. Compare PCA to random projections.",
        "3. Plot reconstruction error vs number of components."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}