{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lesson 14 - k-Means Clustering and Diagnostics\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Objectives\n- Implement k-means clustering from scratch.\n- Track inertia (distortion) across iterations.\n- Visualize cluster assignments.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## From the notes\n\n**k-means**\n- Alternate between assigning points to nearest centroid and updating centroids.\n- Objective: minimize within-cluster squared distances.\n\n_TODO: Validate k-means objective in the CS229 main notes PDF._\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Intuition\nk-means is a coordinate descent algorithm for clustering that repeatedly reassigns points and recomputes centroids.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data\nWe generate three Gaussian clusters for visualization.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nX = np.vstack([\n    np.random.multivariate_normal([0,0], np.eye(2), 80),\n    np.random.multivariate_normal([3,0], np.eye(2), 80),\n    np.random.multivariate_normal([1.5,2.5], np.eye(2), 80),\n])\n\ndef kmeans(X, k=3, iters=20):\n    idx = np.random.choice(len(X), k, replace=False)\n    centroids = X[idx]\n    inertia = []\n    for _ in range(iters):\n        dists = np.linalg.norm(X[:, None, :] - centroids[None, :, :], axis=2)\n        labels = np.argmin(dists, axis=1)\n        centroids = np.array([X[labels==j].mean(axis=0) for j in range(k)])\n        inertia.append(np.sum((X - centroids[labels])**2))\n    return labels, centroids, inertia\n\nlabels, centroids, inertia = kmeans(X, k=3)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Experiments\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "inertia[-1]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualizations\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "plt.figure(figsize=(6,4))\nplt.scatter(X[:,0], X[:,1], c=labels, cmap=\"viridis\", alpha=0.7)\nplt.scatter(centroids[:,0], centroids[:,1], c=\"red\", marker=\"x\", s=100)\nplt.title(\"k-means clusters\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.show()\n\nplt.figure(figsize=(6,4))\nplt.plot(inertia)\nplt.title(\"k-means distortion over iterations\")\nplt.xlabel(\"iteration\")\nplt.ylabel(\"inertia\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Takeaways\n- k-means alternates between assignment and update steps.\n- Inertia provides a diagnostic of convergence.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explain it in an interview\n- Explain why k-means can get stuck in local minima.\n- Describe how k-means relates to EM for Gaussian mixtures.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n- Run k-means with different random seeds and compare centroids.\n- Implement k-means++ initialization.\n- Plot inertia versus k to pick the elbow.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}