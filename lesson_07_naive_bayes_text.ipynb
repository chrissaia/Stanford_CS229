{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lesson 07 - Naive Bayes for Text + Laplace Smoothing\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Objectives\n- Implement multinomial Naive Bayes with Laplace smoothing.\n- Understand the bag-of-words representation.\n- Visualize class log-odds for keywords.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## From the notes\n\n**Naive Bayes**\n- Assume conditional independence: $p(x|y) = \\prod_j p(x_j|y)$.\n- Laplace smoothing: $\\phi_{j|y} = \\frac{\\text{count}(x_j, y) + 1}{\\text{count}(y) + V}$.\n\n_TODO: Validate formulas in the CS229 main notes PDF._\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Intuition\nNaive Bayes multiplies per-word likelihoods, and Laplace smoothing prevents zero probabilities for unseen words.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data\nWe create a toy email dataset with a small vocabulary to illustrate the algorithm.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nvocab = [\"free\", \"money\", \"hello\", \"meeting\", \"offer\", \"project\"]\ndocs = [\n    (\"free money offer\", 1),\n    (\"free offer\", 1),\n    (\"hello project meeting\", 0),\n    (\"project meeting\", 0),\n    (\"free money\", 1),\n    (\"hello meeting\", 0),\n]\n\ndef vectorize(text):\n    tokens = text.split()\n    return np.array([tokens.count(word) for word in vocab])\n\nX = np.vstack([vectorize(t) for t, _ in docs])\ny = np.array([label for _, label in docs])\n\ndef train_nb(X, y, alpha=1.0):\n    V = X.shape[1]\n    class_priors = np.array([np.mean(y==0), np.mean(y==1)])\n    word_counts = np.array([X[y==c].sum(axis=0) for c in [0,1]])\n    total_counts = word_counts.sum(axis=1, keepdims=True)\n    word_probs = (word_counts + alpha) / (total_counts + alpha * V)\n    return class_priors, word_probs\n\npriors, word_probs = train_nb(X, y)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Experiments\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def predict_nb(x):\n    log_probs = np.log(priors) + (x * np.log(word_probs)).sum(axis=1)\n    return np.argmax(log_probs)\n\npreds = np.array([predict_nb(x) for x in X])\n(preds == y).mean()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualizations\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "log_odds = np.log(word_probs[1]) - np.log(word_probs[0])\nplt.figure(figsize=(6,4))\nplt.bar(vocab, log_odds)\nplt.title(\"Naive Bayes log-odds by word\")\nplt.xlabel(\"word\")\nplt.ylabel(\"log odds spam vs ham\")\nplt.xticks(rotation=30)\nplt.show()\n\nplt.figure(figsize=(6,4))\nplt.imshow(word_probs, aspect=\"auto\", cmap=\"viridis\")\nplt.colorbar(label=\"p(word|class)\")\nplt.yticks([0,1], [\"ham\", \"spam\"])\nplt.xticks(range(len(vocab)), vocab, rotation=30)\nplt.title(\"Word likelihoods\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Takeaways\n- Laplace smoothing ensures nonzero likelihoods for unseen words.\n- Naive Bayes can be competitive for text despite its independence assumption.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explain it in an interview\n- Explain how Laplace smoothing changes Naive Bayes probabilities.\n- Describe why Naive Bayes works well for text classification.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n- Add bigrams to the vocabulary and retrain.\n- Try different smoothing constants and observe behavior.\n- Implement Bernoulli Naive Bayes and compare.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}