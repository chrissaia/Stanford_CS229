{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lesson 01 - Intro, Supervised Learning, and Notation\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Objectives\n- Set up CS229 notation and the supervised learning workflow.\n- Connect data, hypothesis space, and loss minimization.\n- Build a tiny linear model from scratch to establish the pattern used later.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## From the notes\n\n**Notation (CS229)**\n- $m$ = number of training examples, $n$ = number of features.\n- $x^{(i)} \\in \\mathbb{R}^{n+1}$ with $x_0^{(i)} = 1$, $y^{(i)}$ target.\n- Hypothesis: $h_\\theta(x) = \\theta^T x$.\n- Cost: $J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$.\n\n**Learning loop**\n1. Choose hypothesis class $\\mathcal{H}$.\n2. Define objective $J(\\theta)$.\n3. Optimize to obtain $\\theta^*$.\n\n_TODO: Validate these definitions against the official CS229 main notes PDF once available._\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Intuition\nSupervised learning is about turning labeled examples into a function that generalizes. We keep the notation simple so every later algorithm reuses the same symbols and workflow.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data\nWe start with a synthetic 1D dataset so the geometry of a line fit is easy to see.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# Synthetic data\nm = 60\nx = np.linspace(0, 10, m)\ny = 2.5 * x + 3.0 + np.random.normal(scale=2.0, size=m)\nX = np.c_[np.ones(m), x]\n\n# Closed-form solution\ntheta = np.linalg.pinv(X.T @ X) @ X.T @ y\npreds = X @ theta\n\ntheta\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Experiments\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Compare mean squared error with a random guess\nmse_model = np.mean((preds - y) ** 2)\nmse_baseline = np.mean((y.mean() - y) ** 2)\nmse_model, mse_baseline\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualizations\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "plt.figure(figsize=(6,4))\nplt.scatter(x, y, alpha=0.7, label=\"data\")\nplt.plot(x, preds, color=\"black\", label=\"linear fit\")\nplt.title(\"Synthetic regression data\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(6,4))\nplt.hist(y - preds, bins=15, alpha=0.7, color=\"tab:orange\")\nplt.title(\"Residual histogram\")\nplt.xlabel(\"error\")\nplt.ylabel(\"count\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Takeaways\n- The CS229 notation (m, n, x^(i), y^(i), \u03b8) is reused in every later lesson.\n- Even a simple linear model demonstrates the full ML workflow: choose h\u03b8, define J(\u03b8), optimize.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explain it in an interview\n- Describe supervised learning as fitting h\u03b8 that minimizes a loss over labeled examples.\n- Explain the role of the bias term x0 = 1 in linear models.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n- Show how the normal equation changes if you add L2 regularization.\n- Why is the bias term included as x0 = 1?\n- Create a dataset where linear regression underfits.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}