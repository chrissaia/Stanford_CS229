{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lesson 19 - Evaluation: ROC, PR, Thresholding\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Objectives\n- Compute confusion matrix, ROC, and PR curves.\n- Explore how thresholds impact precision/recall.\n- Visualize tradeoffs between metrics.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## From the notes\n\n**Evaluation**\n- Confusion matrix: TP, FP, TN, FN.\n- ROC plots TPR vs FPR; PR plots precision vs recall.\n\n_TODO: Validate evaluation definitions in the CS229 main notes PDF._\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Intuition\nEvaluation metrics depend on the operating threshold. ROC and PR curves summarize tradeoffs across thresholds.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data\nWe use synthetic probabilistic scores to illustrate metrics.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\ny_true = np.hstack([np.ones(80), np.zeros(120)])\nscores = np.hstack([\n    np.random.beta(5, 2, 80),\n    np.random.beta(2, 5, 120)\n])\n\ndef confusion_at_thresh(y_true, scores, thresh):\n    preds = scores >= thresh\n    tp = np.sum((preds == 1) & (y_true == 1))\n    fp = np.sum((preds == 1) & (y_true == 0))\n    tn = np.sum((preds == 0) & (y_true == 0))\n    fn = np.sum((preds == 0) & (y_true == 1))\n    return tp, fp, tn, fn\n\ndef roc_pr(y_true, scores, thresholds):\n    tprs, fprs, precs, recalls = [], [], [], []\n    for t in thresholds:\n        tp, fp, tn, fn = confusion_at_thresh(y_true, scores, t)\n        tpr = tp / (tp + fn)\n        fpr = fp / (fp + tn)\n        prec = tp / (tp + fp) if tp + fp > 0 else 0\n        rec = tpr\n        tprs.append(tpr)\n        fprs.append(fpr)\n        precs.append(prec)\n        recalls.append(rec)\n    return np.array(tprs), np.array(fprs), np.array(precs), np.array(recalls)\n\nthresholds = np.linspace(0, 1, 50)\ntprs, fprs, precs, recalls = roc_pr(y_true, scores, thresholds)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Experiments\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Example threshold\nconfusion_at_thresh(y_true, scores, 0.5)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualizations\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "plt.figure(figsize=(6,4))\nplt.plot(fprs, tprs)\nplt.plot([0,1],[0,1], linestyle=\"--\", color=\"gray\")\nplt.title(\"ROC curve\")\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.show()\n\nplt.figure(figsize=(6,4))\nplt.plot(recalls, precs)\nplt.title(\"Precision-Recall curve\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Takeaways\n- ROC curves emphasize ranking performance; PR curves emphasize positive class precision.\n- Thresholds trade off precision and recall.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Explain it in an interview\n- Explain when PR is more informative than ROC.\n- Describe how to pick a threshold for deployment.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n- Compute AUROC and average precision from the curves.\n- Simulate a more imbalanced dataset and compare curves.\n- Plot F1 vs threshold and pick the best point.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}